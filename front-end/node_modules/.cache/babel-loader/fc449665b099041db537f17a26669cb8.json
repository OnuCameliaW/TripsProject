{"ast":null,"code":"var __extends = this && this.__extends || function () {\n  var extendStatics = function (d, b) {\n    extendStatics = Object.setPrototypeOf || {\n      __proto__: []\n    } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p];\n    };\n\n    return extendStatics(d, b);\n  };\n\n  return function (d, b) {\n    extendStatics(d, b);\n\n    function __() {\n      this.constructor = d;\n    }\n\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\n/**\n * @module ol/renderer/webgl/PointsLayer\n */\n\n\nimport WebGLArrayBuffer from '../../webgl/Buffer.js';\nimport { ARRAY_BUFFER, DYNAMIC_DRAW, ELEMENT_ARRAY_BUFFER } from '../../webgl.js';\nimport { AttributeType, DefaultUniform } from '../../webgl/Helper.js';\nimport GeometryType from '../../geom/GeometryType.js';\nimport WebGLLayerRenderer, { colorDecodeId, colorEncodeId, WebGLWorkerMessageType } from './Layer.js';\nimport ViewHint from '../../ViewHint.js';\nimport { buffer, createEmpty, equals } from '../../extent.js';\nimport { apply as applyTransform, create as createTransform, makeInverse as makeInverseTransform, multiply as multiplyTransform } from '../../transform.js';\nimport { create as createWebGLWorker } from '../../worker/webgl.js';\nimport { getUid } from '../../util.js';\nimport WebGLRenderTarget from '../../webgl/RenderTarget.js';\nimport { assert } from '../../asserts.js';\nimport BaseVector from '../../layer/BaseVector.js';\n/**\n * @typedef {Object} CustomAttribute A description of a custom attribute to be passed on to the GPU, with a value different\n * for each feature.\n * @property {string} name Attribute name.\n * @property {function(import(\"../../Feature\").default):number} callback This callback computes the numerical value of the\n * attribute for a given feature.\n */\n\n/**\n * @typedef {Object} Options\n * @property {Array<CustomAttribute>} [attributes] These attributes will be read from the features in the source and then\n * passed to the GPU. The `name` property of each attribute will serve as its identifier:\n *  * In the vertex shader as an `attribute` by prefixing it with `a_`\n *  * In the fragment shader as a `varying` by prefixing it with `v_`\n * Please note that these can only be numerical values.\n * @property {string} vertexShader Vertex shader source, mandatory.\n * @property {string} fragmentShader Fragment shader source, mandatory.\n * @property {string} [hitVertexShader] Vertex shader source for hit detection rendering.\n * @property {string} [hitFragmentShader] Fragment shader source for hit detection rendering.\n * @property {Object.<string,import(\"../../webgl/Helper\").UniformValue>} [uniforms] Uniform definitions for the post process steps\n * Please note that `u_texture` is reserved for the main texture slot.\n * @property {Array<import(\"./Layer\").PostProcessesOptions>} [postProcesses] Post-processes definitions\n */\n\n/**\n * @classdesc\n * WebGL vector renderer optimized for points.\n * All features will be rendered as quads (two triangles forming a square). New data will be flushed to the GPU\n * every time the vector source changes.\n *\n * You need to provide vertex and fragment shaders for rendering. This can be done using\n * {@link module:ol/webgl/ShaderBuilder} utilities. These shaders shall expect a `a_position` attribute\n * containing the screen-space projected center of the quad, as well as a `a_index` attribute\n * whose value (0, 1, 2 or 3) indicates which quad vertex is currently getting processed (see structure below).\n *\n * To include variable attributes in the shaders, you need to declare them using the `attributes` property of\n * the options object like so:\n * ```js\n * new WebGLPointsLayerRenderer(layer, {\n *   attributes: [\n *     {\n *       name: 'size',\n *       callback: function(feature) {\n *         // compute something with the feature\n *       }\n *     },\n *     {\n *       name: 'weight',\n *       callback: function(feature) {\n *         // compute something with the feature\n *       }\n *     },\n *   ],\n *   vertexShader:\n *     // shader using attribute a_weight and a_size\n *   fragmentShader:\n *     // shader using varying v_weight and v_size\n * ```\n *\n * To enable hit detection, you must as well provide dedicated shaders using the `hitVertexShader`\n * and `hitFragmentShader` properties. These shall expect the `a_hitColor` attribute to contain\n * the final color that will have to be output for hit detection to work.\n *\n * The following uniform is used for the main texture: `u_texture`.\n *\n * Please note that the main shader output should have premultiplied alpha, otherwise visual anomalies may occur.\n *\n * Points are rendered as quads with the following structure:\n *\n * ```\n *   (u0, v1)      (u1, v1)\n *  [3]----------[2]\n *   |`           |\n *   |  `         |\n *   |    `       |\n *   |      `     |\n *   |        `   |\n *   |          ` |\n *  [0]----------[1]\n *   (u0, v0)      (u1, v0)\n *  ```\n *\n * This uses {@link module:ol/webgl/Helper~WebGLHelper} internally.\n *\n * @api\n */\n\nvar WebGLPointsLayerRenderer =\n/** @class */\nfunction (_super) {\n  __extends(WebGLPointsLayerRenderer, _super);\n  /**\n   * @param {import(\"../../layer/Layer.js\").default} layer Layer.\n   * @param {Options} options Options.\n   */\n\n\n  function WebGLPointsLayerRenderer(layer, options) {\n    var _this = this;\n\n    var uniforms = options.uniforms || {};\n    var projectionMatrixTransform = createTransform();\n    uniforms[DefaultUniform.PROJECTION_MATRIX] = projectionMatrixTransform;\n    _this = _super.call(this, layer, {\n      uniforms: uniforms,\n      postProcesses: options.postProcesses\n    }) || this;\n    _this.sourceRevision_ = -1;\n    _this.verticesBuffer_ = new WebGLArrayBuffer(ARRAY_BUFFER, DYNAMIC_DRAW);\n    _this.hitVerticesBuffer_ = new WebGLArrayBuffer(ARRAY_BUFFER, DYNAMIC_DRAW);\n    _this.indicesBuffer_ = new WebGLArrayBuffer(ELEMENT_ARRAY_BUFFER, DYNAMIC_DRAW);\n    _this.program_ = _this.helper.getProgram(options.fragmentShader, options.vertexShader);\n\n    if (_this.getShaderCompileErrors()) {\n      throw new Error(_this.getShaderCompileErrors());\n    }\n    /**\n     * @type {boolean}\n     * @private\n     */\n\n\n    _this.hitDetectionEnabled_ = options.hitFragmentShader && options.hitVertexShader ? true : false;\n    _this.hitProgram_ = _this.hitDetectionEnabled_ && _this.helper.getProgram(options.hitFragmentShader, options.hitVertexShader);\n\n    if (_this.getShaderCompileErrors()) {\n      throw new Error(_this.getShaderCompileErrors());\n    }\n\n    var customAttributes = options.attributes ? options.attributes.map(function (attribute) {\n      return {\n        name: 'a_' + attribute.name,\n        size: 1,\n        type: AttributeType.FLOAT\n      };\n    }) : [];\n    /**\n     * A list of attributes used by the renderer. By default only the position and\n     * index of the vertex (0 to 3) are required.\n     * @type {Array<import('../../webgl/Helper.js').AttributeDescription>}\n     */\n\n    _this.attributes = [{\n      name: 'a_position',\n      size: 2,\n      type: AttributeType.FLOAT\n    }, {\n      name: 'a_index',\n      size: 1,\n      type: AttributeType.FLOAT\n    }].concat(customAttributes);\n    /**\n     * A list of attributes used for hit detection.\n     * @type {Array<import('../../webgl/Helper.js').AttributeDescription>}\n     */\n\n    _this.hitDetectionAttributes = [{\n      name: 'a_position',\n      size: 2,\n      type: AttributeType.FLOAT\n    }, {\n      name: 'a_index',\n      size: 1,\n      type: AttributeType.FLOAT\n    }, {\n      name: 'a_hitColor',\n      size: 4,\n      type: AttributeType.FLOAT\n    }, {\n      name: 'a_featureUid',\n      size: 1,\n      type: AttributeType.FLOAT\n    }].concat(customAttributes);\n    _this.customAttributes = options.attributes ? options.attributes : [];\n    _this.previousExtent_ = createEmpty();\n    /**\n     * This transform is updated on every frame and is the composition of:\n     * - invert of the world->screen transform that was used when rebuilding buffers (see `this.renderTransform_`)\n     * - current world->screen transform\n     * @type {import(\"../../transform.js\").Transform}\n     * @private\n     */\n\n    _this.currentTransform_ = projectionMatrixTransform;\n    /**\n     * This transform is updated when buffers are rebuilt and converts world space coordinates to screen space\n     * @type {import(\"../../transform.js\").Transform}\n     * @private\n     */\n\n    _this.renderTransform_ = createTransform();\n    /**\n     * @type {import(\"../../transform.js\").Transform}\n     * @private\n     */\n\n    _this.invertRenderTransform_ = createTransform();\n    /**\n     * @type {Float32Array}\n     * @private\n     */\n\n    _this.renderInstructions_ = new Float32Array(0);\n    /**\n     * These instructions are used for hit detection\n     * @type {Float32Array}\n     * @private\n     */\n\n    _this.hitRenderInstructions_ = new Float32Array(0);\n    /**\n     * @type {WebGLRenderTarget}\n     * @private\n     */\n\n    _this.hitRenderTarget_ = _this.hitDetectionEnabled_ && new WebGLRenderTarget(_this.helper);\n    _this.worker_ = createWebGLWorker();\n\n    _this.worker_.addEventListener('message', function (event) {\n      var received = event.data;\n\n      if (received.type === WebGLWorkerMessageType.GENERATE_BUFFERS) {\n        var projectionTransform = received.projectionTransform;\n\n        if (received.hitDetection) {\n          this.hitVerticesBuffer_.fromArrayBuffer(received.vertexBuffer);\n          this.helper.flushBufferData(this.hitVerticesBuffer_);\n        } else {\n          this.verticesBuffer_.fromArrayBuffer(received.vertexBuffer);\n          this.helper.flushBufferData(this.verticesBuffer_);\n        }\n\n        this.indicesBuffer_.fromArrayBuffer(received.indexBuffer);\n        this.helper.flushBufferData(this.indicesBuffer_);\n        this.renderTransform_ = projectionTransform;\n        makeInverseTransform(this.invertRenderTransform_, this.renderTransform_);\n\n        if (received.hitDetection) {\n          this.hitRenderInstructions_ = new Float32Array(event.data.renderInstructions);\n        } else {\n          this.renderInstructions_ = new Float32Array(event.data.renderInstructions);\n        }\n\n        this.getLayer().changed();\n      }\n    }.bind(_this));\n\n    return _this;\n  }\n  /**\n   * @inheritDoc\n   */\n\n\n  WebGLPointsLayerRenderer.prototype.renderFrame = function (frameState) {\n    var renderCount = this.indicesBuffer_.getSize();\n    this.helper.drawElements(0, renderCount);\n    this.helper.finalizeDraw(frameState);\n    var canvas = this.helper.getCanvas();\n    var layerState = frameState.layerStatesArray[frameState.layerIndex];\n    var opacity = layerState.opacity;\n\n    if (opacity !== parseFloat(canvas.style.opacity)) {\n      canvas.style.opacity = opacity;\n    }\n\n    if (this.hitDetectionEnabled_) {\n      this.renderHitDetection(frameState);\n      this.hitRenderTarget_.clearCachedData();\n    }\n\n    return canvas;\n  };\n  /**\n   * @inheritDoc\n   */\n\n\n  WebGLPointsLayerRenderer.prototype.prepareFrame = function (frameState) {\n    var layer = this.getLayer();\n    var vectorSource = layer.getSource();\n    var viewState = frameState.viewState;\n    var viewNotMoving = !frameState.viewHints[ViewHint.ANIMATING] && !frameState.viewHints[ViewHint.INTERACTING];\n    var extentChanged = !equals(this.previousExtent_, frameState.extent);\n    var sourceChanged = this.sourceRevision_ < vectorSource.getRevision();\n\n    if (sourceChanged) {\n      this.sourceRevision_ = vectorSource.getRevision();\n    }\n\n    if (viewNotMoving && (extentChanged || sourceChanged)) {\n      var projection = viewState.projection;\n      var resolution = viewState.resolution;\n      var renderBuffer = layer instanceof BaseVector ? layer.getRenderBuffer() : 0;\n      var extent = buffer(frameState.extent, renderBuffer * resolution);\n      vectorSource.loadFeatures(extent, resolution, projection);\n      this.rebuildBuffers_(frameState);\n      this.previousExtent_ = frameState.extent.slice();\n    } // apply the current projection transform with the invert of the one used to fill buffers\n\n\n    this.helper.makeProjectionTransform(frameState, this.currentTransform_);\n    multiplyTransform(this.currentTransform_, this.invertRenderTransform_);\n    this.helper.useProgram(this.program_);\n    this.helper.prepareDraw(frameState); // write new data\n\n    this.helper.bindBuffer(this.verticesBuffer_);\n    this.helper.bindBuffer(this.indicesBuffer_);\n    this.helper.enableAttributes(this.attributes);\n    return true;\n  };\n  /**\n   * Rebuild internal webgl buffers based on current view extent; costly, should not be called too much\n   * @param {import(\"../../PluggableMap\").FrameState} frameState Frame state.\n   * @private\n   */\n\n\n  WebGLPointsLayerRenderer.prototype.rebuildBuffers_ = function (frameState) {\n    var layer = this.getLayer();\n    var vectorSource = layer.getSource(); // saves the projection transform for the current frame state\n\n    var projectionTransform = createTransform();\n    this.helper.makeProjectionTransform(frameState, projectionTransform);\n    var features = vectorSource.getFeatures(); // here we anticipate the amount of render instructions that we well generate\n    // this can be done since we know that for normal render we only have x, y as base instructions,\n    // and x, y, r, g, b, a and featureUid for hit render instructions\n    // and we also know the amount of custom attributes to append to these\n\n    var totalInstructionsCount = (2 + this.customAttributes.length) * features.length;\n\n    if (!this.renderInstructions_ || this.renderInstructions_.length !== totalInstructionsCount) {\n      this.renderInstructions_ = new Float32Array(totalInstructionsCount);\n    }\n\n    if (this.hitDetectionEnabled_) {\n      var totalHitInstructionsCount = (7 + this.customAttributes.length) * features.length;\n\n      if (!this.hitRenderInstructions_ || this.hitRenderInstructions_.length !== totalHitInstructionsCount) {\n        this.hitRenderInstructions_ = new Float32Array(totalHitInstructionsCount);\n      }\n    } // loop on features to fill the buffer\n\n\n    var feature;\n    var tmpCoords = [];\n    var tmpColor = [];\n    var renderIndex = 0;\n    var hitIndex = 0;\n    var hitColor;\n\n    for (var i = 0; i < features.length; i++) {\n      feature = features[i];\n\n      if (!feature.getGeometry() || feature.getGeometry().getType() !== GeometryType.POINT) {\n        continue;\n      }\n\n      tmpCoords[0] = feature.getGeometry().getFlatCoordinates()[0];\n      tmpCoords[1] = feature.getGeometry().getFlatCoordinates()[1];\n      applyTransform(projectionTransform, tmpCoords);\n      hitColor = colorEncodeId(hitIndex + 6, tmpColor);\n      this.renderInstructions_[renderIndex++] = tmpCoords[0];\n      this.renderInstructions_[renderIndex++] = tmpCoords[1]; // for hit detection, the feature uid is saved in the opacity value\n      // and the index of the opacity value is encoded in the color values\n\n      if (this.hitDetectionEnabled_) {\n        this.hitRenderInstructions_[hitIndex++] = tmpCoords[0];\n        this.hitRenderInstructions_[hitIndex++] = tmpCoords[1];\n        this.hitRenderInstructions_[hitIndex++] = hitColor[0];\n        this.hitRenderInstructions_[hitIndex++] = hitColor[1];\n        this.hitRenderInstructions_[hitIndex++] = hitColor[2];\n        this.hitRenderInstructions_[hitIndex++] = hitColor[3];\n        this.hitRenderInstructions_[hitIndex++] = Number(getUid(feature));\n      } // pushing custom attributes\n\n\n      var value = void 0;\n\n      for (var j = 0; j < this.customAttributes.length; j++) {\n        value = this.customAttributes[j].callback(feature);\n        this.renderInstructions_[renderIndex++] = value;\n\n        if (this.hitDetectionEnabled_) {\n          this.hitRenderInstructions_[hitIndex++] = value;\n        }\n      }\n    }\n    /** @type {import('./Layer').WebGLWorkerGenerateBuffersMessage} */\n\n\n    var message = {\n      type: WebGLWorkerMessageType.GENERATE_BUFFERS,\n      renderInstructions: this.renderInstructions_.buffer,\n      customAttributesCount: this.customAttributes.length\n    }; // additional properties will be sent back as-is by the worker\n\n    message['projectionTransform'] = projectionTransform;\n    this.worker_.postMessage(message, [this.renderInstructions_.buffer]);\n    this.renderInstructions_ = null;\n    /** @type {import('./Layer').WebGLWorkerGenerateBuffersMessage} */\n\n    if (this.hitDetectionEnabled_) {\n      var hitMessage = {\n        type: WebGLWorkerMessageType.GENERATE_BUFFERS,\n        renderInstructions: this.hitRenderInstructions_.buffer,\n        customAttributesCount: 5 + this.customAttributes.length\n      };\n      hitMessage['projectionTransform'] = projectionTransform;\n      hitMessage['hitDetection'] = true;\n      this.worker_.postMessage(hitMessage, [this.hitRenderInstructions_.buffer]);\n      this.hitRenderInstructions_ = null;\n    }\n  };\n  /**\n   * @inheritDoc\n   */\n\n\n  WebGLPointsLayerRenderer.prototype.forEachFeatureAtCoordinate = function (coordinate, frameState, hitTolerance, callback, declutteredFeatures) {\n    assert(this.hitDetectionEnabled_, 66);\n\n    if (!this.hitRenderInstructions_) {\n      return;\n    }\n\n    var pixel = applyTransform(frameState.coordinateToPixelTransform, coordinate.slice());\n    var data = this.hitRenderTarget_.readPixel(pixel[0], pixel[1]);\n    var color = [data[0] / 255, data[1] / 255, data[2] / 255, data[3] / 255];\n    var index = colorDecodeId(color);\n    var opacity = this.hitRenderInstructions_[index];\n    var uid = Math.floor(opacity).toString();\n    var source = this.getLayer().getSource();\n    var feature = source.getFeatureByUid(uid);\n\n    if (feature) {\n      return callback(feature, this.getLayer());\n    }\n  };\n  /**\n   * Render the hit detection data to the corresponding render target\n   * @param {import(\"../../PluggableMap.js\").FrameState} frameState current frame state\n   */\n\n\n  WebGLPointsLayerRenderer.prototype.renderHitDetection = function (frameState) {\n    // skip render entirely if vertex buffers not ready/generated yet\n    if (!this.hitVerticesBuffer_.getSize()) {\n      return;\n    }\n\n    this.hitRenderTarget_.setSize(frameState.size);\n    this.helper.useProgram(this.hitProgram_);\n    this.helper.prepareDrawToRenderTarget(frameState, this.hitRenderTarget_, true);\n    this.helper.bindBuffer(this.hitVerticesBuffer_);\n    this.helper.bindBuffer(this.indicesBuffer_);\n    this.helper.enableAttributes(this.hitDetectionAttributes);\n    var renderCount = this.indicesBuffer_.getSize();\n    this.helper.drawElements(0, renderCount);\n  };\n  /**\n   * @inheritDoc\n   */\n\n\n  WebGLPointsLayerRenderer.prototype.disposeInternal = function () {\n    this.worker_.terminate();\n\n    _super.prototype.disposeInternal.call(this);\n  };\n\n  return WebGLPointsLayerRenderer;\n}(WebGLLayerRenderer);\n\nexport default WebGLPointsLayerRenderer;","map":null,"metadata":{},"sourceType":"module"}